import streamlit as st
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import re
from deep_translator import GoogleTranslator
from nltk.corpus import stopwords
import nltk
import logging
import chardet

# Download NLTK stopwords
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Page Configuration ---
st.set_page_config(
    page_title="DuoScan P√©dagogique",
    page_icon="ü¶â",
    layout="wide"
)


# --- Utility Functions ---
def nettoyer_texte(texte):
    """Clean text by converting to lowercase, removing punctuation, numbers, and stopwords."""
    if not texte or not isinstance(texte, str):
        return ""
    texte = texte.lower()
    texte = re.sub(r'[^\w\s]', '', texte)  # Remove punctuation
    texte = re.sub(r'\d+', '', texte)  # Remove numbers
    stop_words = set(stopwords.words('french')) | set(['duolingo', 'lapplication', 'cest'])
    texte = " ".join(word for word in texte.split() if word not in stop_words)
    return texte


def translate_to_english(texte):
    """Translate French text to English for VADER analysis."""
    try:
        return GoogleTranslator(source='fr', target='en').translate(texte)
    except Exception as e:
        logger.error(f"Translation error: {e}")
        return texte  # Fallback to original text


analyzer = SentimentIntensityAnalyzer()


def analyser_sentiment(texte):
    """Analyze sentiment using VADER on translated text with French negative term detection."""
    if not texte or not texte.strip():
        return "Neutre üòê"

    # Lexique fran√ßais pour termes fortement n√©gatifs
    negative_terms = {'nul', 'nulle', 'horrible', 'affreux', 'd√©testable', 'p√©nible', 'aga√ßant', 'ennuyeux'}
    texte_lower = texte.lower()

    # V√©rifier si le texte contient des termes n√©gatifs explicites
    if any(term in texte_lower.split() for term in negative_terms):
        return "N√©gatif üëé"

    # Traduire en anglais pour VADER
    texte_en = translate_to_english(texte)
    vs = analyzer.polarity_scores(texte_en)
    compound_score = vs['compound']

    # Seuils ajust√©s pour plus de sensibilit√©
    if compound_score >= 0.05:
        return "Positif üëç"
    elif compound_score <= -0.05:
        return "N√©gatif üëé"
    else:
        return "Neutre üòê"


def generer_nuage_mots(textes, titre_section):
    """Generate word cloud from list of texts."""
    if not textes:
        st.info(f"Pas de donn√©es suffisantes pour g√©n√©rer le nuage de mots {titre_section.lower()}.")
        return

    texte_concatene = " ".join(nettoyer_texte(txt) for txt in textes if txt)
    if not texte_concatene.strip():
        st.info(f"Pas de mots significatifs pour le nuage {titre_section.lower()}.")
        return

    try:
        wordcloud = WordCloud(
            width=800, height=400,
            background_color='rgba(255, 255, 255, 0)',
            collocations=False,
            prefer_horizontal=0.9,
            min_font_size=10
        ).generate(texte_concatene)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis("off")
        st.pyplot(fig)
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du nuage de mots '{titre_section}': {e}")


def detect_encoding(file):
    """Detect file encoding."""
    raw_data = file.read()
    result = chardet.detect(raw_data)
    file.seek(0)
    return result['encoding']


# --- Sidebar ---
with st.sidebar:
    st.image("https://i.imgur.com/LF3KIQa.jpeg", width=100, caption="EL FILALI MOHAMED")
    st.markdown("# DuoScan P√©dagogique ü¶â")
    st.divider()
    st.markdown("**Master :** Ing√©nierie Technop√©dagogique et Innovation")
    st.markdown("**Module :** Design de l'Exp√©rience d'Apprentissage")
    st.markdown("**Professeur :** M. Adil AMMAR")
    st.markdown("**R√©alis√© par :** KHALIL JABER")
    st.divider()
    st.markdown("### Objectif de l'outil:")
    st.info(
        "Analyser le sentiment des retours utilisateurs de Duolingo "
        "pour identifier des pistes d'am√©lioration des exp√©riences d'apprentissage."
    )
    st.markdown("### Guide Rapide")
    st.markdown("""
    1. Choisissez la m√©thode d'entr√©e.
    2. Fournissez les avis Duolingo.
    3. Cliquez sur "üöÄ Analyser les Avis".
    4. Explorez les insights !
    """)
    st.divider()
    st.caption(f"¬© {pd.Timestamp.now().year} - ITPI")

# --- Main Interface ---
st.title("ü¶â DuoScan P√©dagogique")
st.subheader("Analyse des Avis Utilisateurs de Duolingo pour l'Optimisation des Exp√©riences d'Apprentissage")
st.markdown("Cet outil analyse les sentiments exprim√©s dans les avis Duolingo.")
st.divider()

# --- Data Input Section ---
st.header("üì• 1. Soumettre les Avis Duolingo")
input_method = st.radio(
    "Comment souhaitez-vous fournir les avis ?",
    ("Coller le texte directement", "T√©l√©charger un fichier (.txt ou .csv)"),
    key="input_method_choice",
    horizontal=True
)

avis_entres_bruts = []

if input_method == "Coller le texte directement":
    avis_texte_area = st.text_area(
        "Collez ici les avis Duolingo (un par ligne) :",
        height=150,
        key="text_area_input",
        placeholder="Exemple : Duolingo m'a vraiment aid√© √† apprendre l'espagnol, c'est ludique !\nLes notifications sont trop insistantes."
    )
    if avis_texte_area:
        avis_entres_bruts = [avis.strip() for avis in avis_texte_area.split('\n') if avis.strip()]

elif input_method == "T√©l√©charger un fichier (.txt ou .csv)":
    uploaded_file = st.file_uploader(
        "S√©lectionnez un fichier .txt (un avis par ligne) ou .csv (colonne 'avis' ou unique colonne)",
        type=["txt", "csv"],
        key="file_uploader_input"
    )
    if uploaded_file is not None:
        try:
            encoding = detect_encoding(uploaded_file)
            if uploaded_file.name.endswith('.txt'):
                avis_entres_bruts = [line.decode(encoding).strip() for line in uploaded_file if
                                     line.decode(encoding).strip()]
            elif uploaded_file.name.endswith('.csv'):
                df_avis = pd.read_csv(uploaded_file, encoding=encoding)
                if 'avis' in df_avis.columns:
                    avis_entres_bruts = [str(avis).strip() for avis in df_avis['avis'].dropna().tolist() if
                                         str(avis).strip()]
                elif len(df_avis.columns) == 1:
                    avis_entres_bruts = [str(avis).strip() for avis in df_avis.iloc[:, 0].dropna().tolist() if
                                         str(avis).strip()]
                else:
                    st.error("Fichier CSV : utilisez une colonne nomm√©e 'avis' ou une seule colonne.")
                    st.stop()
        except Exception as e:
            st.error(f"‚ö†Ô∏è Erreur lors de la lecture du fichier : {e}. Essayez un fichier encod√© en UTF-8.")
            st.stop()

# --- Analysis Button ---
st.divider()
if st.button("üöÄ Analyser les Avis Duolingo", type="primary", use_container_width=True, key="analyze_button"):
    if not avis_entres_bruts:
        st.warning("‚ö†Ô∏è Veuillez fournir des avis Duolingo avant de lancer l'analyse.")
        st.stop()

    # Limit input size
    if len(avis_entres_bruts) > 1000:
        st.warning("‚ö†Ô∏è Trop d'avis fournis (limite : 1000). Veuillez r√©duire la taille du dataset.")
        st.stop()

    st.header("üìä 2. Analyse des Sentiments")
    with st.spinner("ü¶â Analyse en cours..."):
        avis_analyses = []
        sentiments_counts = {"Positif üëç": 0, "N√©gatif üëé": 0, "Neutre üòê": 0}
        avis_positifs_textes = []
        avis_negatifs_textes = []

        for i, avis_texte in enumerate(avis_entres_bruts):
            sentiment = analyser_sentiment(avis_texte)
            avis_analyses.append({"id": i + 1, "texte_original": avis_texte, "sentiment_detecte": sentiment})
            sentiments_counts[sentiment] += 1
            if sentiment == "Positif üëç":
                avis_positifs_textes.append(avis_texte)
            elif sentiment == "N√©gatif üëé":
                avis_negatifs_textes.append(avis_texte)

        st.toast('Analyse termin√©e ! üéâ', icon='‚úÖ')

        # --- Key Metrics ---
        st.subheader("üìà Vue d'Ensemble")
        cols_metriques = st.columns(4)
        cols_metriques[0].metric("Total Avis Analys√©s", len(avis_analyses))
        cols_metriques[1].metric("Avis Positifs üëç", sentiments_counts["Positif üëç"])
        cols_metriques[2].metric("Avis N√©gatifs üëé", sentiments_counts["N√©gatif üëé"])
        cols_metriques[3].metric("Avis Neutres üòê", sentiments_counts["Neutre üòê"])

        if sum(sentiments_counts.values()) > 0:
            df_sentiments = pd.DataFrame(list(sentiments_counts.items()), columns=['Sentiment', 'Nombre'])
            sentiment_color_map = {
                "Positif üëç": "#28a745",
                "N√©gatif üëé": "#dc3545",
                "Neutre üòê": "#6c757d"
            }
            fig = px.bar(
                df_sentiments,
                x='Sentiment',
                y='Nombre',
                color='Sentiment',
                color_discrete_map=sentiment_color_map,
                labels={'Nombre': "Nombre d'Avis", 'Sentiment': 'Cat√©gorie de Sentiment'},
                text_auto=True
            )
            fig.update_layout(
                showlegend=False,
                xaxis_title=None,
                yaxis_title="Nombre d'Avis",
                font=dict(family="sans-serif", size=12),
                margin=dict(l=20, r=20, t=30, b=20),
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)',
            )
            fig.update_traces(textposition='outside')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Aucune donn√©e √† afficher dans le graphique.")

        st.divider()
        # --- Detailed Analysis ---
        with st.expander("üîç Explorer chaque avis", expanded=False):
            if avis_analyses:
                df_details = pd.DataFrame(avis_analyses)
                df_details = df_details[['id', 'sentiment_detecte', 'texte_original']]
                df_details.rename(columns={'id': 'ID', 'sentiment_detecte': 'Sentiment D√©tect√©',
                                           'texte_original': 'Texte de l\'Avis'}, inplace=True)
                st.dataframe(df_details, use_container_width=True, hide_index=True)
            else:
                st.info("Aucun avis √† afficher en d√©tail.")

        st.divider()
        # --- Word Clouds ---
        st.subheader("‚òÅÔ∏è Termes Fr√©quents")
        show_wordclouds = st.checkbox("Afficher les nuages de mots", value=True, key="show_wc")
        if show_wordclouds:
            if not avis_positifs_textes and not avis_negatifs_textes:
                st.info("Pas assez de donn√©es textuelles pour g√©n√©rer les nuages de mots.")
            else:
                tab_positif, tab_negatif = st.tabs(["Termes Positifs", "Termes N√©gatifs"])
                with tab_positif:
                    generer_nuage_mots(avis_positifs_textes, "issus des Avis Positifs")
                with tab_negatif:
                    generer_nuage_mots(avis_negatifs_textes, "issus des Avis N√©gatifs")
        st.divider()

        # --- Interpretation Section ---
        st.header("üí° 3. Pistes pour l'Exp√©rience d'Apprentissage")
        positive_ratio = sentiments_counts["Positif üëç"] / len(avis_analyses) if avis_analyses else 0
        negative_ratio = sentiments_counts["N√©gatif üëé"] / len(avis_analyses) if avis_analyses else 0
        insights = []
        if positive_ratio > 0.5:
            insights.append(
                "‚úÖ Les utilisateurs appr√©cient majoritairement Duolingo, probablement gr√¢ce √† son aspect ludique.")
        if negative_ratio > 0.3:
            insights.append(
                "‚ö†Ô∏è De nombreuses frustrations √©mergent, potentiellement li√©es √† des publicit√©s ou restrictions.")
        if avis_positifs_textes:
            insights.append(
                "üí° Points forts : examinez les termes dans les avis positifs pour identifier les fonctionnalit√©s pl√©biscit√©es.")
        if avis_negatifs_textes:
            insights.append("üîç Points √† am√©liorer : les termes n√©gatifs indiquent des irritants UX √† corriger.")

        if insights:
            st.markdown("### Insights Automatiques")
            for insight in insights:
                st.markdown(f"- {insight}")

        st.markdown("""
            √Ä partir des sentiments et termes identifi√©s :
            * Quels sont les **points forts** per√ßus par les utilisateurs ?
            * Quelles **frustrations ou difficult√©s** √©mergent ?
            * Comment ces retours √©clairent-ils les **principes de design UX** ?
            * Quelles **recommandations** pour am√©liorer l'exp√©rience p√©dagogique ?
        """)
        st.text_area(
            "R√©digez votre analyse et recommandations pour M. AMMAR :",
            height=200,
            key="interpretation_area_detailed",
            placeholder="Exemple : Les avis positifs soulignent la gamification. Les termes n√©gatifs comme 'publicit√©s' sugg√®rent des interruptions..."
        )
else:
    st.info("‚ÑπÔ∏è Pr√™t √† scanner les avis Duolingo ? Fournissez des donn√©es et cliquez sur 'Analyser'.")